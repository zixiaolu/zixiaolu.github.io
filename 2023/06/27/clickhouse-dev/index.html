<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>clickHouse-dev | InIt</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="ClickHouse的基本部署1.安装官方推荐的安装方式在本地部署的时候并没有安装成功，这里是按照rpm安装指南中的信息，用比较复杂的方式使用rpm安装成功： 123456789101112131415161718192021通过rpm中的指引找到了官方存储rpm服务的地址:https:&#x2F;&#x2F;packages.clickhouse.com&#x2F;rpm&#x2F;stable&#x2F;挑其中的一个版本对应的将基本依赖的rp">
<meta property="og:type" content="article">
<meta property="og:title" content="clickHouse-dev">
<meta property="og:url" content="http://example.com/2023/06/27/clickhouse-dev/index.html">
<meta property="og:site_name" content="InIt">
<meta property="og:description" content="ClickHouse的基本部署1.安装官方推荐的安装方式在本地部署的时候并没有安装成功，这里是按照rpm安装指南中的信息，用比较复杂的方式使用rpm安装成功： 123456789101112131415161718192021通过rpm中的指引找到了官方存储rpm服务的地址:https:&#x2F;&#x2F;packages.clickhouse.com&#x2F;rpm&#x2F;stable&#x2F;挑其中的一个版本对应的将基本依赖的rp">
<meta property="og:locale">
<meta property="article:published_time" content="2023-06-27T09:52:00.000Z">
<meta property="article:modified_time" content="2023-07-05T05:56:11.895Z">
<meta property="article:author" content="zixiaolu">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="InIt" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">InIt</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Suche"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-clickhouse-dev" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/27/clickhouse-dev/" class="article-date">
  <time class="dt-published" datetime="2023-06-27T09:52:00.000Z" itemprop="datePublished">2023-06-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      clickHouse-dev
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="ClickHouse的基本部署"><a href="#ClickHouse的基本部署" class="headerlink" title="ClickHouse的基本部署"></a>ClickHouse的基本部署</h1><h2 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h2><p>官方推荐的安装方式在本地部署的时候并没有安装成功，这里是按照rpm安装指南中的信息，用比较复杂的方式使用rpm安装成功：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">通过rpm中的指引找到了官方存储rpm服务的地址:</span><br><span class="line">https://packages.clickhouse.com/rpm/stable/</span><br><span class="line"></span><br><span class="line">挑其中的一个版本对应的将基本依赖的rpm下载，然后使用rpm -ivh进行安装</span><br><span class="line">clickhouse-client-23.2.4.12.x86_64.rpm</span><br><span class="line">clickhouse-common-static-23.2.4.12.x86_64.rpm</span><br><span class="line">clickhouse-common-static-dbg-23.2.4.12.aarch64.rpm</span><br><span class="line">clickhouse-keeper-23.2.4.12.x86_64.rpm</span><br><span class="line">clickhouse-server-23.2.4.12.x86_64.rpm</span><br><span class="line"></span><br><span class="line">安装完成后，可以直接使用命令启动服务:</span><br><span class="line">sudo /etc/init.d/clickhouse-server start</span><br><span class="line">停止服务则可以使用如下命令:</span><br><span class="line">sudo /etc/init.d/clickhouse-server stop</span><br><span class="line"></span><br><span class="line">第一次启动服务的时候需要输入default用户的密码,设置完成后可以使用如下命令登录：</span><br><span class="line">clickhouse-client -h ip地址 -d default -m -u default --password 密码明文</span><br><span class="line"></span><br><span class="line">访问本机的clickhouse可以直接使用:</span><br><span class="line">clickhouse-client --password 密码明文 </span><br><span class="line">将默认使用defalut用户登录</span><br></pre></td></tr></table></figure>
<h2 id="2-配置"><a href="#2-配置" class="headerlink" title="2.配置"></a>2.配置</h2><p>默认在&#x2F;etc&#x2F;clickhouse-server目录下，会生成两个配置文件：config.xml与user.xml<br>config.xml用于配置clickhouse服务的设置<br>user.xml则是配置关于clickhouse用户信息的配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">关于config.xml中的一些配置</span><br><span class="line">    &lt;!-- Port for HTTP API. See also &#x27;https_port&#x27; for secure connections.</span><br><span class="line">         This interface is also used by ODBC and JDBC drivers (DataGrip, Dbeaver, ...)</span><br><span class="line">         and by most of web interfaces (embedded UI, Grafana, Redash, ...).</span><br><span class="line">         简而言之JDBC也会复用这个端口</span><br><span class="line">      --&gt;</span><br><span class="line">    &lt;http_port&gt;8123&lt;/http_port&gt;</span><br><span class="line">    &lt;!-- Port for interaction by native protocol with:</span><br><span class="line">         - clickhouse-client and other native ClickHouse tools (clickhouse-benchmark, clickhouse-copier);</span><br><span class="line">         - clickhouse-server with other clickhouse-servers for distributed query processing;</span><br><span class="line">         - ClickHouse drivers and applications supporting native protocol</span><br><span class="line">         (this protocol is also informally called as &quot;the TCP protocol&quot;);</span><br><span class="line">         See also &#x27;tcp_port_secure&#x27; for secure connections.</span><br><span class="line">         原生的clickHouse客户端使用这个端口</span><br><span class="line">    --&gt;</span><br><span class="line">    &lt;tcp_port&gt;9000&lt;/tcp_port&gt;</span><br><span class="line">    &lt;!-- Compatibility with MySQL protocol.</span><br><span class="line">         ClickHouse will pretend to be MySQL for applications connecting to this port.</span><br><span class="line">    --&gt;</span><br><span class="line">    &lt;mysql_port&gt;9004&lt;/mysql_port&gt;</span><br><span class="line">    &lt;!-- Compatibility with PostgreSQL protocol.</span><br><span class="line">         ClickHouse will pretend to be PostgreSQL for applications connecting to this port.</span><br><span class="line">    --&gt;</span><br><span class="line">    &lt;postgresql_port&gt;9005&lt;/postgresql_port&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- Listen specified address.</span><br><span class="line">        Use :: (wildcard IPv6 address), if you want to accept connections both with IPv4 and IPv6 from everywhere.</span><br><span class="line">        Notes:</span><br><span class="line">        If you open connections from wildcard address, make sure that at least one of the following measures applied:</span><br><span class="line">        - server is protected by firewall and not accessible from untrusted networks;</span><br><span class="line">        - all users are restricted to subset of network addresses (see users.xml);</span><br><span class="line">        - all users have strong passwords, only secure (TLS) interfaces are accessible, or connections are only made via TLS interfaces.</span><br><span class="line">        - users without password have readonly access.</span><br><span class="line">        See also: https://www.shodan.io/search?query=clickhouse</span><br><span class="line">        修改控制访问的IP,跟大多数配置文件一样,“::”表示任何地址都能够访问</span><br><span class="line">    --&gt;</span><br><span class="line">    &lt;listen_host&gt;::&lt;/listen_host&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- Maximum memory usage (resident set size) for server process.</span><br><span class="line">         Zero value or unset means default. Default is &quot;max_server_memory_usage_to_ram_ratio&quot; of available physical RAM.</span><br><span class="line">         If the value is larger than &quot;max_server_memory_usage_to_ram_ratio&quot; of available physical RAM, it will be cut down.</span><br><span class="line"></span><br><span class="line">         The constraint is checked on query execution time.</span><br><span class="line">         If a query tries to allocate memory and the current memory usage plus allocation is greater</span><br><span class="line">          than specified threshold, exception will be thrown.</span><br><span class="line"></span><br><span class="line">         It is not practical to set this constraint to small values like just a few gigabytes,</span><br><span class="line">          because memory allocator will keep this amount of memory in caches and the server will deny service of queries.</span><br><span class="line">        最大内存限制,这个限制是clickHouse独立的,与物理机无关,设定超过了物理机内存的阈值肯定也是会受到物理机限制的.</span><br><span class="line">        参数的单位是bytes,填写为0时无上限,同时内存限制不仅仅受到该参数影响.</span><br><span class="line">      --&gt;</span><br><span class="line">    &lt;max_server_memory_usage&gt;0&lt;/max_server_memory_usage&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- On memory constrained environments you may have to set this to value larger than 1.</span><br><span class="line">        这个参数与max_server_memory_usage同时作用,构成了限制clickhouse的内存消耗的参数.</span><br><span class="line">      --&gt;</span><br><span class="line">    &lt;max_server_memory_usage_to_ram_ratio&gt;0.9&lt;/max_server_memory_usage_to_ram_ratio&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- Path to data directory, with trailing slash. </span><br><span class="line">         该参数设定clickhouse的数据磁盘存储位置,在该参数下还有挂载盘符的设置storage_configuration,切换多盘符挂载的方式默认不开启</span><br><span class="line">    --&gt;</span><br><span class="line">    &lt;path&gt;/var/lib/clickhouse/&lt;/path&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- Path to temporary data for processing hard queries. </span><br><span class="line">         查询时获取查询结果聚合前得到的结果的缓存目录</span><br><span class="line">    --&gt;</span><br><span class="line">    &lt;tmp_path&gt;/var/lib/clickhouse/tmp/&lt;/tmp_path&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>此处列举解释了一些个人认为重要与需要调整的参数,更多的参数解释可以前往官方文档查看<br><a target="_blank" rel="noopener" href="https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings">https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">关于user.xml中的一些配置</span><br><span class="line">最简单的一个用户例</span><br><span class="line">    &lt;zxl&gt;                            &lt;!--用户名,这个标签需要在users标签下使用--&gt;</span><br><span class="line">        &lt;name&gt;zxl&lt;/name&gt;</span><br><span class="line">        &lt;password&gt;qwerty&lt;/password&gt;  &lt;!--密码的配置有很多种,存储的密码可以直接使用明文,</span><br><span class="line">                                         也可以调整为经过加密后的密文,</span><br><span class="line">                                         注意不使用明文密码时标签的使用,原版配置文件中有使用例可供参考--&gt;</span><br><span class="line">        &lt;networks&gt;</span><br><span class="line">            &lt;ip&gt;::/0&lt;/ip&gt;</span><br><span class="line">        &lt;/networks&gt;</span><br><span class="line">        &lt;profile&gt;default&lt;/profile&gt;   &lt;!--DDL权限管理,在文件中的&lt;profiles&gt;标签中可以配置,可以限制读写操作--&gt;</span><br><span class="line">        &lt;quota&gt;default&lt;/quota&gt;       &lt;!--查询限制标签,在文件中的&lt;quotas&gt;标签中可以配置,可以对标签用户的查询进行一定的限制--&gt;</span><br><span class="line">        &lt;access_management&gt;1&lt;/access_management&gt;</span><br><span class="line">    &lt;/zxl&gt;</span><br></pre></td></tr></table></figure>
<p>更多的user.xml中的配置可以参考如下文章:<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35423190/article/details/109726587">https://blog.csdn.net/qq_35423190/article/details/109726587</a></p>
<h2 id="3-数据库操作"><a href="#3-数据库操作" class="headerlink" title="3.数据库操作"></a>3.数据库操作</h2><p>创建数据库：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREAT DATABAES IF NOT EXISTS db_name [ENGINE=enigne]</span><br><span class="line">--</span><br><span class="line">CREATE DATABASE IF NOT EXISTS zombie_log;</span><br></pre></td></tr></table></figure>
<p>这里主要注意一下对应数据库的引擎:<br><a target="_blank" rel="noopener" href="https://clickhouse.com/docs/zh/engines/database-engines">https://clickhouse.com/docs/zh/engines/database-engines</a><br>在2.10版本后,数据库的默认引擎从Ordinary变为了Atomic。</p>
<p>创建完成数据库后,在 …&#x2F;clickhouse&#x2F;metadata 中会创建一个快捷方式指向对应 …&#x2F;clickhouse&#x2F;store 中的文件夹用于指明该数据库信息在数据库中的location。<br>同时可以在对应的sql文件中也能查看到对应数据库的locationId与engine。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@local metadata]# ll</span><br><span class="line">总用量 40</span><br><span class="line">lrwxrwxrwx 1 clickhouse clickhouse   67 5月  15 17:24 default -&gt; /var/lib/clickhouse/store/ff6/ff6f63b7-2f08-4d21-b09a-8978b8d29904/</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse   78 5月  15 17:24 default.sql</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 5月  15 17:24 information_schema</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 5月  15 17:24 INFORMATION_SCHEMA</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse   51 5月  15 17:24 information_schema.sql</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse   51 5月  15 17:24 INFORMATION_SCHEMA.sql</span><br><span class="line">lrwxrwxrwx 1 clickhouse clickhouse   67 5月  15 17:24 system -&gt; /var/lib/clickhouse/store/013/013b6c19-31b7-46be-9e50-cb984829122f/</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse   78 5月  15 17:24 system.sql</span><br><span class="line">lrwxrwxrwx 1 clickhouse clickhouse   67 6月  28 17:47 zombie_log -&gt; /var/lib/clickhouse/store/732/732bbfa1-a95d-4728-bb6d-d57838d76001/</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse   78 6月  28 17:47 zombie_log.sql</span><br><span class="line"></span><br><span class="line">[root@local metadata]# cd ../store/732/732bbfa1-a95d-4728-bb6d-d57838d76001/</span><br><span class="line">[root@local 732bbfa1-a95d-4728-bb6d-d57838d76001]#</span><br><span class="line">---------------------------------------------------------------------------------</span><br><span class="line">[root@local metadata]# cat zombie_log.sql </span><br><span class="line">ATTACH DATABASE _ UUID &#x27;732bbfa1-a95d-4728-bb6d-d57838d76001&#x27;</span><br><span class="line">ENGINE = Atomic</span><br></pre></td></tr></table></figure>
<p>在metadata目录下,也有information_schema这样的数据库没有对应的指向到store中的数据库,这与其采用的数据库引擎相关</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@local metadata]# cat information_schema.sql </span><br><span class="line">ATTACH DATABASE information_schema</span><br><span class="line">ENGINE = Memory</span><br></pre></td></tr></table></figure>
<p>Memory引擎用于存放临时数据，这种数据库的表都只会存在于内存中，是临时的数据库。</p>
<p>创建数据表：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE table.name(</span><br><span class="line">    name1 type,</span><br><span class="line">    name2 type,</span><br><span class="line">    ...</span><br><span class="line">)</span><br><span class="line">ENGINE = engine</span><br><span class="line">PARTITION BY partition_index</span><br><span class="line">ORDER BY order_index</span><br><span class="line">SAMPLE BY sample_index</span><br><span class="line">...</span><br><span class="line">---</span><br><span class="line">CREATE TABLE zombie_log.insert_test</span><br><span class="line">(</span><br><span class="line">	`col1` String,</span><br><span class="line">	`col2` String,</span><br><span class="line">	`col3` BIGINT,</span><br><span class="line">)</span><br><span class="line">ENGINE = MergeTree()</span><br><span class="line">ORDER BY (col3/1000)</span><br><span class="line">PARTITION BY toDate(col3/1000)</span><br><span class="line"></span><br><span class="line">ENGINE-&gt;数据表引擎</span><br><span class="line">-MergeTree：最基础的数据表引擎，包含一，二级索引，数据分区与数据TTL等特性</span><br><span class="line">-ReplacingMergeTree：去重的数据表，基本特性继承MergeTree，但是在Merge合并操作中有独特的实现用于数据去重。</span><br><span class="line">-SummingMergeTree：取和的数据表，在合并过程中，会按照Order By中定义的排序键进行去重取和，输出。</span><br><span class="line">-AggregatingMergeTree：聚合的数据表，会在指定的字段中生成聚合数据，在合并时根据Order by进行合并，</span><br><span class="line">并使用对应的聚合缓存进行合并，查询加速。</span><br><span class="line">-CollapsingMergeTree：实现了行级修改的数据表引擎，针对于列式存储中的劣势，定义修改或删除按照新增操作进行设定。</span><br><span class="line"></span><br><span class="line">Order By-&gt;数据表的排序条件</span><br><span class="line">数据表将按定义的排序列从左到右对表进行排序</span><br><span class="line">大多数情况下，数据表的排序条件前缀与指定的Primary key的需要一致，防止主键顺序与排序顺序不一致。</span><br><span class="line"></span><br><span class="line">PARTITION BY-&gt;数据表的分区键</span><br><span class="line">用于为数据表定义分区分块，是MergeTree的特性，合理的数据分区能够显著提高效率。</span><br></pre></td></tr></table></figure>
<p>执行完成创建表后，clickhouse会在metadata目录下生成对应表的sql，通过这些sql文件，可以获得表结构与生成表时大致的语句。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@local zombie_log]# pwd</span><br><span class="line">/var/lib/clickhouse/metadata/zombie_log</span><br><span class="line">[root@local zombie_log]# ll</span><br><span class="line">总用量 8</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 192 6月  29 14:13 insert_test1.sql</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 225 6月  29 10:17 insert_test.sql</span><br><span class="line">[root@local zombie_log]# cat insert_test.sql </span><br><span class="line">ATTACH TABLE _ UUID &#x27;b9662409-7920-41d6-98ce-2563e4075b90&#x27;</span><br><span class="line">(</span><br><span class="line">    `col1` String,</span><br><span class="line">    `col2` String,</span><br><span class="line">    `col3` Int64</span><br><span class="line">)</span><br><span class="line">ENGINE = MergeTree</span><br><span class="line">PARTITION BY toDate(col3 / 1000)</span><br><span class="line">ORDER BY col3 / 1000</span><br><span class="line">SETTINGS index_granularity = 8192</span><br></pre></td></tr></table></figure>
<p>PARTITION BY相关：<br>一般来说，分区键不会影响查询速度，即不携带指定分区返回的查询时，分区并不会加快对应的查询速度。在clickhouse中数据分区更多的作用是为了更方便的删改数据，官方推荐对于一个表来说，分区数目最好不要超过1000，这与linux系统下的文件描述符相关。<br>当然，也可以使用分区键进行对应的加速查询，可以使用clickhouse的解释器查看对应的执行情况。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">先查询一下目标表的分区情况</span><br><span class="line">Local :) SELECT partition  FROM system.parts WHERE (database IN (&#x27;zombie_log&#x27;)) AND (table IN (&#x27;insert_test&#x27;));</span><br><span class="line"></span><br><span class="line">SELECT partition</span><br><span class="line">FROM system.parts</span><br><span class="line">WHERE (database IN (&#x27;zombie_log&#x27;)) AND (table IN (&#x27;insert_test&#x27;))</span><br><span class="line"></span><br><span class="line">Query id: c83ac0a2-a775-481a-a305-ec2f32d6c32f</span><br><span class="line"></span><br><span class="line">┌─partition──┐</span><br><span class="line">│ 2023-06-29 │</span><br><span class="line">│ 2023-06-30 │</span><br><span class="line">└────────────┘</span><br><span class="line"></span><br><span class="line">2 rows in set. Elapsed: 0.004 sec.</span><br><span class="line">不使用指定分区进行查询</span><br><span class="line">Local :) EXPLAIN actions=1 SELECT * from zombie_log.insert_test where col1 =&#x27;Value 10.8590367908679233&#x27;;</span><br><span class="line">┌─explain──────────────────────────────────────┐</span><br><span class="line">│ Expression ((Projection + Before ORDER BY))  │</span><br><span class="line">│ Actions: INPUT :: 0 -&gt; col1 String : 0       │</span><br><span class="line">│          INPUT :: 1 -&gt; col2 String : 1       │</span><br><span class="line">│          INPUT :: 2 -&gt; col3 Int64 : 2        │</span><br><span class="line">│ Positions: 0 1 2                             │</span><br><span class="line">│   ReadFromMergeTree (zombie_log.insert_test) │</span><br><span class="line">│   ReadType: Default                          │</span><br><span class="line">│   Parts: 2                                   │</span><br><span class="line">│   Granules: 136                              │</span><br><span class="line">└──────────────────────────────────────────────┘</span><br><span class="line">可以看到这个SQL取出了2个分区进行查询</span><br><span class="line">Local :) EXPLAIN actions=1 SELECT * from zombie_log.insert_test where col1 =&#x27;Value 10.8590367908679233&#x27; and toDate(col3/1000) = &#x27;2023-06-29&#x27;;</span><br><span class="line">接下来再按照对应的分区键进行查询</span><br><span class="line">┌─explain──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐</span><br><span class="line">│ Expression ((Projection + Before ORDER BY))                                                                                                                                                                                                  │</span><br><span class="line">│ Actions: INPUT :: 0 -&gt; col3 Int64 : 0                                                                                                                                                                                                        │</span><br><span class="line">│          INPUT :: 1 -&gt; col1 String : 1                                                                                                                                                                                                       │</span><br><span class="line">│          INPUT :: 2 -&gt; col2 String : 2                                                                                                                                                                                                       │</span><br><span class="line">│ Positions: 1 2 0                                                                                                                                                                                                                             │</span><br><span class="line">│   Filter (WHERE)                                                                                                                                                                                                                             │</span><br><span class="line">│   Filter column: and(equals(toDate(divide(col3, 1000)), &#x27;2023-06-29&#x27;), equals(col1, &#x27;Value 10.8590367908679233&#x27;)) (removed)                                                                                                                  │</span><br><span class="line">│   Actions: INPUT : 0 -&gt; equals(toDate(divide(col3, 1000)), &#x27;2023-06-29&#x27;) UInt8 : 0                                                                                                                                                           │</span><br><span class="line">│            INPUT :: 1 -&gt; col3 Int64 : 1                                                                                                                                                                                                      │</span><br><span class="line">│            INPUT : 2 -&gt; col1 String : 2                                                                                                                                                                                                      │</span><br><span class="line">│            INPUT :: 3 -&gt; col2 String : 3                                                                                                                                                                                                     │</span><br><span class="line">│            COLUMN Const(String) -&gt; &#x27;Value 10.8590367908679233&#x27; String : 4                                                                                                                                                                    │</span><br><span class="line">│            FUNCTION equals(col1 : 2, &#x27;Value 10.8590367908679233&#x27; :: 4) -&gt; equals(col1, &#x27;Value 10.8590367908679233&#x27;) UInt8 : 5                                                                                                                │</span><br><span class="line">│            FUNCTION and(equals(toDate(divide(col3, 1000)), &#x27;2023-06-29&#x27;) :: 0, equals(col1, &#x27;Value 10.8590367908679233&#x27;) :: 5) -&gt; and(equals(toDate(divide(col3, 1000)), &#x27;2023-06-29&#x27;), equals(col1, &#x27;Value 10.8590367908679233&#x27;)) UInt8 : 4 │</span><br><span class="line">│   Positions: 1 2 3 4                                                                                                                                                                                                                         │</span><br><span class="line">│     ReadFromMergeTree (zombie_log.insert_test)                                                                                                                                                                                               │</span><br><span class="line">│     ReadType: Default                                                                                                                                                                                                                        │</span><br><span class="line">│     Parts: 1                                                                                                                                                                                                                                 │</span><br><span class="line">│     Granules: 62                                                                                                                                                                                                                             │</span><br><span class="line">└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘</span><br><span class="line">可以看到对应的Parts只调用了1，其跳过了分区日期为2023-06-30的分片进行查询。</span><br></pre></td></tr></table></figure>
<p>使用分区查询时，如果目标明确为指定分区的数据，可以减少执行器调取的分区数据文件，但是clickhouse本身不保证数据的唯一性，所以可能存在主键相同的数据，如果需要查询目标数据却不清楚其所在分区，可能会导致因为只选取了指定分区数据而导致数据无法正常查询的问题。</p>
<p>表中数据操作：<br>数据库基本操作CRUD<br>Insert操作与Select操作<br>Clickhouse的写入SQL与可以兼容常规的SQL，在使用CLI命令时，可以通过insert SQL进行插入数据，每次执行一个完整的insert插入数据时，MergeTree会在分区表与目录下添加等待合并的数据记录，约每10分钟到15分钟，clickhouse会执行一次Merge操作，将当前产生的非分区数据进行合并，按照分区规则合并&#x2F;生成一个分区中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">首先查看当前表中数据结构</span><br><span class="line">Local :) SELECT partition,name,part_type,active FROM system.parts WHERE (database IN (&#x27;zombie_log&#x27;)) AND (table IN (&#x27;insert_test&#x27;));</span><br><span class="line">┌─partition──┬─name───────────────────┬─part_type─┬─active─┐</span><br><span class="line">│ 2023-06-29 │ 20230629_224_232_1_234 │ Wide      │      1 │</span><br><span class="line">│ 2023-06-30 │ 20230630_222_231_1_234 │ Wide      │      1 │</span><br><span class="line">└────────────┴────────────────────────┴───────────┴────────┘</span><br><span class="line">[root@local insert_test]# pwd</span><br><span class="line">/var/lib/clickhouse/data/zombie_log/insert_test</span><br><span class="line">[root@local insert_test]# ll</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  30 18:03 20230629_224_232_1_234</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  30 18:03 20230630_222_231_1_234</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  29 10:17 detached-rw-r----- 1 clickhouse clickhouse    1 6月  29 10:17 format_version.txt</span><br><span class="line">使用代码向这个表插入10w条数据，其中一半是下一天的，一半是当天的（按照分区键进行区分）</span><br><span class="line">Local :) SELECT partition,name,part_type,active FROM system.parts WHERE (database IN (&#x27;zombie_log&#x27;)) AND (table IN (&#x27;insert_test&#x27;));</span><br><span class="line">┌─partition──┬─name───────────────────┬─part_type─┬─active─┐</span><br><span class="line">│ 2023-06-29 │ 20230629_224_232_1_234 │ Wide      │      1 │</span><br><span class="line">│ 2023-06-30 │ 20230630_222_231_1_234 │ Wide      │      1 │</span><br><span class="line">│ 2023-07-01 │ 20230701_235_235_0     │ Compact   │      1 │</span><br><span class="line">└────────────┴────────────────────────┴───────────┴────────┘</span><br><span class="line">[root@local insert_test]# ll</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  30 18:03 20230629_224_232_1_234</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  30 18:03 20230630_222_231_1_234</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  30 18:21 20230701_235_235_0</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  29 10:17 detached</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse    1 6月  29 10:17 format_version.txt</span><br><span class="line">使用一次批量插入后，产生了一个新的以7月1日为分区键的分区，分区类型为Compact；</span><br></pre></td></tr></table></figure>
<p>分区文件目录的名称命名，在clickhouse中也有对应的含义：<br>20230630_222_231_1_234 20230630-&gt;分区键数据 222-&gt;最小数据块编码 231-&gt;最大数据块编码 1-&gt;合并次数 234-&gt;最大mutation操作</p>
<p>part_type主要分为wide与compact两种类型，当分区数据较少时使用Compact类型存储数据，分区数据达到一定的数据时使用Wide类型存储数据，这个参数可以使用min_bytes_for_wide_part 和min_rows_for_wide_part进行限制，以自动区分Wide分区与Compact分区。<br>两者的本质上的区别实际上是存储数据方式不同，Wide分区中数据是按照列区分，将每一列的数据放到一个文件中存储，而Compact分区则是在数据量不多时，将所有的列都存储在一个文件中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">硬盘中Wide分区的文件结构</span><br><span class="line">[root@local insert_test]# ll ./20230630_222_231_1_234/</span><br><span class="line">总用量 20244</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse      404 6月  29 16:15 checksums.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 10322809 6月  29 16:15 col1.bin</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse     1800 6月  29 16:15 col1.mrk2</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 10328639 6月  29 16:15 col2.bin</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse     1800 6月  29 16:15 col2.mrk2</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse    30883 6月  29 16:15 col3.bin</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse     1800 6月  29 16:15 col3.mrk2</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse       78 6月  29 16:15 columns.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse        6 6月  29 16:15 count.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse       10 6月  29 16:15 default_compression_codec.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse       16 6月  29 16:15 minmax_col3.idx</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse        2 6月  29 16:15 partition.dat</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse      600 6月  29 16:15 primary.idx</span><br><span class="line">Compact分区的文件结构</span><br><span class="line">[root@local insert_test]# ll ./20230701_235_235_0/</span><br><span class="line">总用量 3404</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse     258 6月  30 18:21 checksums.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse      78 6月  30 18:21 columns.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse       6 6月  30 18:21 count.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 3450060 6月  30 18:21 data.bin</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse     728 6月  30 18:21 data.mrk3</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse      10 6月  30 18:21 default_compression_codec.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse      16 6月  30 18:21 minmax_col3.idx</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse       2 6月  30 18:21 partition.dat</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse     104 6月  30 18:21 primary.idx</span><br><span class="line">从上述的文件结构中可以观察到，分区文件结构中，对应的文件除去每列指定的文件之外共同的文件结构为</span><br><span class="line"> checksums.txt   ----  校验文件，明文，用于快速检查除去数据文件之外的文件是否正确</span><br><span class="line"> columns.txt     ----  列信息文件，明文，查看时可以直接看到对应的列名</span><br><span class="line"> count.txt       ----  计数文件，明文，用于记录当前分区的全部数据</span><br><span class="line"> default_compression_codec.txt ---- 压缩格式信息文件，明文，表面当前分区使用的压缩格式</span><br><span class="line"> minmax_col3.idx   ---- 分区索引文件，二进制保存，用于保存当前分区中主键最小与最大值，该文件在查询中可以加速对应查询</span><br><span class="line"> partition.dat     ---- 分区文件，二进制保存，用于保存分区表达键</span><br><span class="line"> primary.idx       ---- 索引文件，二进制保存，用于映射到.mrk文件中的数据</span><br><span class="line">剩余的两个文件</span><br><span class="line"> [Column].bin  --- 数据文件，数据库的实际数据将会被存储在该文件中</span><br><span class="line"> [Column].mrk  --- 标记文件，用于连接索引与数据文件的桥梁，通过该文件才能将idx文件映射到bin文件中</span><br></pre></td></tr></table></figure>
<p>索引，标记与数据块：<br>clickhouse会根据主键自动生成一级索引，一级索引会根据设定的index_granularity间隔，为数据表生成对应的索引。这个对应的index_granularity在当前版本下存在自适应属性，即会根据数据表的长度自动生成间隔长度，每一段间隔中保存 index_granularity 步长的信息，然后按照这个间隔数据进行编号，保存，这样的一个间隔区间就被叫做MarkRange。</p>
<p>使用索引进行查找的时候，会根据merge_tree_coarse_index_granulartiy &#x3D; N （默认为8），从最大的区间进行拆分，如果当前分区能够被拆分为N个区间，则将分区进行拆分，然后逐一比对当前的<br>区间是否包含目标区间，对于命中区间则继续进行拆分直到原数据无法被N进行拆分，此时取出对应的索引信息，然后将获得的索引信息取出进行区间合并，得到一系列的区间数据。<br>仅仅获取了索引对于数据库来说仍然是找不到数据的，在clickhouse中，索引与标记文件是搭配作用的，在了解标记文件如何生效之前，还得了解clickhouse究竟是如何存储数据到bin文件的。</p>
<p>clickhouse在数据存储时，会使用压缩算法优化存储空间，压缩算法的实现在bin文件中也能体现。clickhouse通过拆分数据块，按照有序的格式将每一部分数据压缩进bin文件中。存储在bin文件中的数据块的结构中体现了压缩算法：对于一个压缩数据块，数据库将他们识别为两部分，一部分是头文件，另一部分是压缩数据文件，头文件中保存了当前数据块的压缩算法，压缩前数据大小与压缩后数据大小。一个压缩数据块的数据量被数据块的min_compress_block_size与max_compress_block_size所限制，规定了在一个数据块未被压缩时最大与最小的数据块大小，这个数据的默认值为64kb-1Mb之间。该默认值也是clickhouse的开发团队认为在压缩效率与速度上相对优秀的一个数据量（可见<a target="_blank" rel="noopener" href="https://groups.google.com/g/clickhouse/c/eUrsP30VtSU/m/p4-pxgdXAgAJ?pli=1%EF%BC%89%E3%80%82">https://groups.google.com/g/clickhouse/c/eUrsP30VtSU/m/p4-pxgdXAgAJ?pli=1）。</a></p>
<p>在实现了数据按块存储后，一方面数据获得一个不错的压缩效率与读取速度，另一方面，其同样的为查询进行了一定的加速，分块的逻辑使得每次数据库查询数据时不必将文件全部打开，读取指定的数据块即可获得对应的数据。</p>
<p>.mrk文件，是用于索引映射到bin文件的工具，在索引中获取的行号起始值与offset偏移量，会被.mrk文件进一步的翻译，使得当前的查询获取到对应数据在bin文件中的数据块与偏移量，然后将对应的bin文件读取到内存中取出数据，这就构成了一次完整的使用索引进行搜索的过程。需要注意使用select查询时，同样也需要尽量满足最左前缀的需求，只有这样才能满足大量剪枝的情况。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">mrk文件中会存储两个数据：</span><br><span class="line">压缩文件中offset    解压缩文件中的offset</span><br><span class="line">索引中的每一行记录，都对应mrk中的每一行数据，可以按照索引中的编号在mrk文件中获取对应的压缩文件偏移量与解压缩文件偏移量。</span><br><span class="line">然后将对应的压缩文件取出，再按照对应的解压缩文件偏移量获取对应的区间起始点，之后即可从该区间中获取对应的数据。</span><br><span class="line">一个wide分区的索引文件内容</span><br><span class="line">[root@local 20230629_224_232_1_234]# od -l -j 0 -N 80 --width=8 primary.idx</span><br><span class="line">0000000  4744866904408856723</span><br><span class="line">0000010  4744866904408919638</span><br><span class="line">0000020  4744866904408982553</span><br><span class="line">0000030  4744866904409041273</span><br><span class="line">0000040  4744866904409095799</span><br><span class="line">0000050  4744866904409158713</span><br><span class="line">0000060  4744866904409234211</span><br><span class="line">0000070  4744866904409297125</span><br><span class="line">0000100  4744866904409355846</span><br><span class="line">0000110  4744866904409418760</span><br><span class="line">0000120</span><br><span class="line">上述索引中对应的mrk2文件内容，其中第一列为压缩文件偏移量，第二列为该分区中的解压文件起始偏移量，第三行表示该分块存储的index_granularity步长信息</span><br><span class="line">这里对于分区的数据量&gt;=64kb且&lt;=1Mb，所以每一个分区都恰好对应一个压缩文件块，第二列表示的解压文件偏移量为0</span><br><span class="line">[root@local 20230629_224_232_1_234]# od -l -j 0 -N 240 --width=24 ./col1.mrk2</span><br><span class="line">0000000                    0                    0                 8192</span><br><span class="line">0000030               141030                    0                 8192</span><br><span class="line">0000060               282133                    0                 8192</span><br><span class="line">0000110               423047                    0                 8192</span><br><span class="line">0000140               564344                    0                 8192</span><br><span class="line">0000170               705224                    0                 8192</span><br><span class="line">0000220               845997                    0                 8192</span><br><span class="line">0000250               987000                    0                 8192</span><br><span class="line">0000300              1128115                    0                 8192</span><br><span class="line">0000330              1269003                    0                 8192</span><br><span class="line">0000360</span><br></pre></td></tr></table></figure>
<p>primary.idx在对应的查询因为文件大小不大，同时为了提高效率，该稀疏索引文件将常驻内存。同时在了解了索引的工作原理之后，为了保证索引有一个良好的工作效率，在确定主键的时候也尽量选择区分度中等的一些键值，更加便于相关数据的聚合。</p>
<p>Update与Delete操作：<br>OLAP数据库在设计上对Update与Delete操作就不友好，因为数据量较大，对于删除与更新这种对数据进行修改的操作代价较大。<br>这类操作在clickhouse中被统称为突变(mutation)操作。突变操作是一个开销不小的操作，clickhouse会将这些操作与merge操作一样，排入一个后台异步程序中进行操作，所以在进行mutation操作时的数据库可能会出现mutation前后的数据分区同时存在。<br>可以通过命令获取当前数据库等待执行的突变操作计划。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">Local :) alter table zombie_log.insert_test delete where col3 = 1688026527188;</span><br><span class="line">Local :) alter table zombie_log.insert_test delete where col3 = 1688026527187;</span><br><span class="line">Local :) select database,table,command,mutation_id from system.mutations;</span><br><span class="line">┌─database───┬─table───────┬─command───────────────────────────┬─mutation_id──────┐</span><br><span class="line">│ zombie_log │ insert_test │ DELETE WHERE col3 = 1688026527187 │ mutation_233.txt │</span><br><span class="line">│ zombie_log │ insert_test │ DELETE WHERE col3 = 1688026527188 │ mutation_234.txt │</span><br><span class="line">└────────────┴─────────────┴───────────────────────────────────┴──────────────────┘</span><br><span class="line">这里就存在了两个等待执行的mutation操作，同时可以在磁盘中找到对应的执行mutation操作的文件</span><br><span class="line">[root@local insert_test]# pwd</span><br><span class="line">/var/lib/clickhouse/data/zombie_log/insert_test</span><br><span class="line">[root@local insert_test]# ll</span><br><span class="line">总用量 40</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  29 16:17 20230629_224_232_1</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  30 18:01 20230629_224_232_1_233</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  30 18:03 20230629_224_232_1_234</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  29 16:15 20230630_222_231_1</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  30 18:01 20230630_222_231_1_233</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  30 18:03 20230630_222_231_1_234</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  29 10:17 detached</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse    1 6月  29 10:17 format_version.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse   95 6月  30 18:01 mutation_233.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse   95 6月  30 18:03 mutation_234.txt</span><br><span class="line">可以查看这两个mutation文件，其中存储的是mutation操作语句与创建时间</span><br><span class="line">[root@local insert_test]# cat mutation_233.txt </span><br><span class="line">format version: 1</span><br><span class="line">create time: 2023-06-30 18:01:39</span><br><span class="line">commands: DELETE WHERE col3 = 1688026527187</span><br><span class="line">[root@local insert_test]# cat mutation_234.txt </span><br><span class="line">format version: 1</span><br><span class="line">create time: 2023-06-30 18:03:36</span><br><span class="line">commands: DELETE WHERE col3 = 1688026527188</span><br></pre></td></tr></table></figure>
<p>如果是通过<br>数据库默认Atomic引擎在执行 DROP&#x2F;DETACH TABLES 命令时,并不会直接删除disk中保存的数据,而是会将对应的数据移动到…&#x2F;clickhouse&#x2F;metadata_dropped 中等待异步删除,异步删除的时间默认设定为8min,该时间可以通过调整配置文件进行修改：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/clickhouse-server/config.d/database_atomic_delay_before_drop_table.xml</span><br><span class="line">&lt;clickhouse&gt;</span><br><span class="line">    &lt;database_atomic_delay_before_drop_table_sec&gt;1&lt;/database_atomic_delay_before_drop_table_sec&gt;</span><br><span class="line">&lt;/clickhouse&gt;</span><br></pre></td></tr></table></figure>
<p>也可以在执行命令后添加 no delay 参数,此时的删除操作将被设定为强制同步,即在分片表中删除数据时,磁盘中dropped目录下的文件同时被删除。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">使用alter命令也可以对应的修改表结构</span><br><span class="line">Local :) ALTER  table zombie_log.insert_test1 modify column col1 IPv4;</span><br><span class="line"></span><br><span class="line">ALTER TABLE zombie_log.insert_test1</span><br><span class="line">    MODIFY COLUMN `col1` IPv4</span><br><span class="line">Ok.</span><br><span class="line"></span><br><span class="line">[root@local insert_test1]# pwd</span><br><span class="line">/var/lib/clickhouse/data/zombie_log/insert_test1</span><br><span class="line">[root@local insert_test1]# ll</span><br><span class="line">总用量 12</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 6月  29 14:13 detached</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse    1 6月  29 14:13 format_version.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse   87 7月   4 11:13 mutation_101.txt</span><br><span class="line">[root@local insert_test1]# cat mutation_101.txt </span><br><span class="line">format version: 1</span><br><span class="line">create time: 2023-07-04 11:13:55</span><br><span class="line">commands: MODIFY COLUMN `col1` IPv4</span><br></pre></td></tr></table></figure>
<p>对分区进行操作删除时（执行Delete操作），ClickHouse并不会立刻删除对应的数据，而是将对应分区的active置为0<br>同时为了防止有新的分片数据进入该分区，ClickHouse会对该分区设置一个新的active为1，且数据为空的分区记录，用于防止在清理分区碎片前，新数据到达该分区<br>此时通过select语句等方法进行查询时，会从该新的active为1的分区中取出数据</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/27/clickhouse-dev/" data-id="cljpaj3hx0000nctpfx8o26sa" data-title="clickHouse-dev" class="article-share-link">Teilen</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2023/03/29/clickHouse-start/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Älter</strong>
      <div class="article-nav-title">clickHouse-start</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">March 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/06/27/clickhouse-dev/">clickHouse-dev</a>
          </li>
        
          <li>
            <a href="/2023/03/29/clickHouse-start/">clickHouse-start</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 zixiaolu<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>